# -*- coding: utf-8 -*-
"""Tabular_Data_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cx0W63cuNYkVWH93wEwrWclBGoLMWG9D
"""

!pip install opendatasets --quiet
import opendatasets as od
od.download("https://www.kaggle.com/datasets/mssmartypants/rice-type-classification")

import torch
import torch.nn as nn
from torch.optim import Adam
from torch.utils.data import DataLoader ,Dataset
from torchsummary import summary
from sklearn.model_selection import train_test_split # Split the dataset (train, validation, test)
from sklearn.metrics import accuracy_score # Calculate the testing Accuracy
import matplotlib.pyplot as plt # Plotting the training progress at the end
import pandas as pd # Data reading and preprocessing
import numpy as np # Mathematical operations

device = 'cuda' if torch.cuda.is_available() else 'cpu'
device

data_df=pd.read_csv("/content/rice-type-classification/riceClassification.csv")
data_df.dropna(inplace=True)
data_df.drop(["id"] , axis=1 ,inplace=True)
print("Output possibilities: ", data_df["Class"].unique()) # Possible Outputs
print("Data Shape (rows, cols): ", data_df.shape) # Print data shape
data_df.head()

"""Normalize the data"""

data_df.shape

data_df.Class.value_counts()

data_df.iloc[0]

# Example: Scatter plot of Area vs. MajorAxisLength colored by Class
plt.figure(figsize=(8, 5))
plt.scatter(data_df['Area'], data_df['MajorAxisLength'], c=data_df['Class'], cmap='viridis')
plt.xlabel('Area')
plt.ylabel('MajorAxisLength')
plt.title('Area vs MajorAxisLength by Class')
plt.colorbar(label='Class')
plt.show()

import matplotlib.pyplot as plt

# Plot histograms for all features
data_df.hist(bins=30, figsize=(12, 8))
plt.suptitle("Feature Distributions")
plt.tight_layout()
plt.show()

before_normalize_data= data_df.copy()
for col in data_df.columns :
  data_df[col]=data_df[col]/data_df[col].abs().max()
data_df.head()

"""split data

Training Size 70%

Validation Size 15%

Testing Size 15%
"""

#df.iloc[ row_selection , column_selection ]
X=np.array(data_df.iloc[:,:-1])
Y=np.array(data_df.iloc[:,-1])
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3) # Create the training split
X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5) # Create the validation split
print("Training set is: ", X_train.shape[0], " rows which is ", round(X_train.shape[0]/data_df.shape[0],4)*100, "%") # Print training shape
print("Validation set is: ",X_val.shape[0], " rows which is ", round(X_val.shape[0]/data_df.shape[0],4)*100, "%") # Print validation shape
print("Testing set is: ",X_test.shape[0], " rows which is ", round(X_test.shape[0]/data_df.shape[0],4)*100, "%") # Print testing shape

class dataset(Dataset):
    def __init__(self, X, Y):
        self.X = torch.tensor(X, dtype = torch.float32).to(device)
        self.Y = torch.tensor(Y, dtype = torch.float32).to(device)

    def __len__(self):
        return len(self.X)
    def __getitem__(self, index):
        return self.X[index], self.Y[index]

training_data = dataset(X_train, y_train)
validation_data = dataset(X_val, y_val)
testing_data = dataset(X_test, y_test)

BATCH_SIZE = 32
EPOCHS = 100
HIDDEN_NEURONS = 10
LR =0.1

train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle= True)
validation_dataloader = DataLoader(validation_data, batch_size=BATCH_SIZE, shuffle= True)
testing_dataloader = DataLoader(testing_data, batch_size=BATCH_SIZE, shuffle= True)

from torch import nn
class MyModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.layer_1 = nn.Linear(X.shape[1], HIDDEN_NEURONS)
        self.layer_2 = nn.Linear(HIDDEN_NEURONS, HIDDEN_NEURONS)
        self.layer_3 = nn.Linear(HIDDEN_NEURONS, out_features=1)
        self.relu = nn.ReLU() # <- add in ReLU activation function
        # Can also put sigmoid in the model
        # This would mean you don't need to use it on the predictions
        # self.sigmoid = nn.Sigmoid()

    def forward(self, x):
      # Intersperse the ReLU activation function between layers
       return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))

model = MyModel().to(device)
print(model)

"""Params=(number of inputs×number of outputs)+number of outputs (biases)

When you create:

**nn.Linear(in_features, out_features)**

PyTorch automatically includes:

**Weights: shape → (out_features, in_features)**

**Bias: shape → (out_features,) (one bias per output neuron)**

Unless you set bias=False, every output neuron has exactly one bias term
"""

model = MyModel().to(device)
summary(model, (X.shape[1],))

criterion = nn.BCEWithLogitsLoss()
optimizer = torch.optim.SGD(model.parameters(), lr= LR)

# Assuming you have these from your code
from sklearn.metrics import accuracy_score
import torch

# Lists to store metrics
total_loss_train = []
total_loss_val = []
total_acc_train = []
total_acc_val = []

# Training loop (example)
num_epochs = 100  # Adjust based on your setup
for epoch in range(num_epochs):
    # Training phase
    model.train()
    train_loss = 0.0
    train_preds = []
    train_labels = []
    for inputs, labels in train_dataloader:
        inputs, labels = inputs.to(device), labels.to(device)
        labels = labels.float()  # Ensure labels are float
        optimizer.zero_grad()
        outputs = model(inputs).squeeze()  # Shape: [batch_size]
        loss = criterion(outputs, labels)  # Shapes match
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
        preds = (torch.sigmoid(outputs) > 0.5).float().cpu().numpy()  # Threshold at 0.5
        train_preds.extend(preds)
        train_labels.extend(labels.cpu().numpy())

    train_loss /= len(train_dataloader)
    train_acc = accuracy_score(train_labels, train_preds)
    total_loss_train.append(train_loss)
    total_acc_train.append(train_acc)

    # Validation phase (similar changes)
    model.eval()
    val_loss = 0.0
    val_preds = []
    val_labels = []
    with torch.no_grad():
        for inputs, labels in validation_dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            labels = labels.float()  # Ensure labels are float
            outputs = model(inputs).squeeze()  # Shape: [batch_size]
            loss = criterion(outputs, labels)  # Shapes match
            val_loss += loss.item()
            preds = (torch.sigmoid(outputs) > 0.5).float().cpu().numpy()
            val_preds.extend(preds)
            val_labels.extend(labels.cpu().numpy())

    val_loss /= len(validation_dataloader)
    val_acc = accuracy_score(val_labels, val_preds)
    total_loss_val.append(val_loss)
    total_acc_val.append(val_acc)

    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')

def predict_single_row(model, row, device):
    model.eval()
    with torch.no_grad():
        if isinstance(row, torch.Tensor):
            row_tensor = row.clone().detach().to(device).unsqueeze(0)
        else:
            row_tensor = torch.tensor(row, dtype=torch.float32).to(device).unsqueeze(0)

        output = model(row_tensor)

        # Binary classification case
        predicted_class = torch.round(torch.sigmoid(output)).item()
    return predicted_class

# Pick a row and its true label
row = X_test[0]  # first row from test set
true_label = y_test[0].item()

# Predict
predicted = predict_single_row(model, row, device)

print(f"True label: {true_label}")
print(f"Predicted label: {predicted}")

### TESTING ###
model.eval()
total_loss_test = 0
total_acc_test = 0

with torch.inference_mode():
    for inputs, labels in testing_dataloader:
        inputs, labels = inputs.to(device), labels.to(device)

        # Forward pass
        y_logits = model(inputs).squeeze(1)
        y_pred = torch.round(torch.sigmoid(y_logits))

        # Loss
        loss = criterion(y_logits, labels)
        total_loss_test += loss.item()

        # Accuracy
        total_acc_test += (y_pred == labels).sum().item()

# Print test results
print(f"Test Loss: {total_loss_test / len(testing_dataloader):.4f} | "
      f"Test Acc: {total_acc_test / len(testing_data) * 100:.2f}%")

fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))

axs[0].plot(total_loss_train, label='Training Loss')
axs[0].plot(total_loss_val, label='Validation Loss')
axs[0].set_title('Training and Validation Loss over Epochs')
axs[0].set_xlabel('Epochs')
axs[0].set_ylabel('Loss')
axs[0].set_ylim([0, 2])
axs[0].legend()

axs[1].plot(total_loss_train, label='Training Accuracy')
axs[1].plot(total_loss_val, label='Validation Accuracy')
axs[1].set_title('Training and Validation Accuracy over Epochs')
axs[1].set_xlabel('Epochs')
axs[1].set_ylabel('Accuracy')
axs[1].set_ylim([0, 100])
axs[1].legend()

plt.tight_layout()

plt.show()

model.eval()
with torch.inference_mode():
  # 3. Make sure the calculations are done with the model and data on the same device
  # in our case, we haven't setup device-agnostic code yet so our data and model are
  # on the CPU by default.
  # model_0.to(device)
  # X_test = X_test.to(device)
  X_test_tensor = torch.FloatTensor(X_test)
  y_test_tensor = torch.FloatTensor(y_test).unsqueeze(1)
  device = torch.device("cpu")
  y_preds = model(X_test_tensor)
y_preds

import matplotlib.pyplot as plt
import torch

# Convert tensors to NumPy for plotting
y_preds_numpy = y_preds.cpu().numpy()
y_test_numpy = y_test_tensor.cpu().numpy()

plt.figure(figsize=(8, 5))
plt.plot(y_test_numpy, label="Actual", marker='o')
plt.plot(y_preds_numpy, label="Predicted", marker='x')

plt.title("Model Predictions vs Actual Values")
plt.xlabel("Sample Index")
plt.ylabel("Value")
plt.legend()
plt.grid(True)
plt.show()

import torch

# 1. Take one sample from your dataset
single_row = X_test_tensor[0]  # first row
true_label = y_test_tensor[0]  # correct label

# 2. Add batch dimension (model expects [batch_size, features])
single_row = single_row.unsqueeze(0)

# 3. Put model in evaluation mode and disable gradients
model.eval()
with torch.inference_mode():
    pred_logits = model(single_row)  # raw output (logits)
    pred_prob = torch.sigmoid(pred_logits)  # convert to probability for binary classification
    pred_class = torch.round(pred_prob)  # 0 or 1

# 4. Show result
print(f"True label: {true_label.item()}")
print(f"Predicted probability: {pred_prob.item():.4f}")
print(f"Predicted class: {int(pred_class.item())}")

plt.figure(figsize=(8,5))
plt.plot(total_loss_train, label='Train Loss')
plt.plot(total_loss_val, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training vs Validation Loss')
plt.legend()
plt.show()