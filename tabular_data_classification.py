# -*- coding: utf-8 -*-
"""Tabular_Data_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cx0W63cuNYkVWH93wEwrWclBGoLMWG9D
"""

!pip install opendatasets --quiet
import opendatasets as od
od.download("https://www.kaggle.com/datasets/mssmartypants/rice-type-classification")

import torch
import torch.nn as nn
from torch.optim import Adam
from torch.utils.data import DataLoader ,Dataset
from torchsummary import summary
from sklearn.model_selection import train_test_split # Split the dataset (train, validation, test)
from sklearn.metrics import accuracy_score # Calculate the testing Accuracy
import matplotlib.pyplot as plt # Plotting the training progress at the end
import pandas as pd # Data reading and preprocessing
import numpy as np # Mathematical operations

import random
def set_seeds(seed=42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seeds(42)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
device

data_df=pd.read_csv("/content/rice-type-classification/riceClassification.csv")
data_df.dropna(inplace=True)
data_df.drop(["id"] , axis=1 ,inplace=True)
print("Output possibilities: ", data_df["Class"].unique()) # Possible Outputs
print("Data Shape (rows, cols): ", data_df.shape) # Print data shape
data_df.head()

"""Normalize the data"""

data_df.shape

data_df.Class.value_counts()

data_df.iloc[0]

# Example: Scatter plot of Area vs. MajorAxisLength colored by Class
plt.figure(figsize=(8, 5))
plt.scatter(data_df['Area'], data_df['MajorAxisLength'], c=data_df['Class'], cmap='viridis')
plt.xlabel('Area')
plt.ylabel('MajorAxisLength')
plt.title('Area vs MajorAxisLength by Class')
plt.colorbar(label='Class')
plt.show()

import matplotlib.pyplot as plt

# Plot histograms for all features
data_df.hist(bins=30, figsize=(12, 8))
plt.suptitle("Feature Distributions")
plt.tight_layout()
plt.show()

from sklearn.preprocessing import StandardScaler

# Split FIRST, then normalize
X = np.array(data_df.iloc[:,:-1])
Y = np.array(data_df.iloc[:,-1])
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)
X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

"""split data

Training Size 70%

Validation Size 15%

Testing Size 15%
"""



class dataset(Dataset):
    def __init__(self, X, Y):
        self.X = torch.tensor(X, dtype = torch.float32).to(device)
        self.Y = torch.tensor(Y, dtype = torch.float32).to(device)

    def __len__(self):
        return len(self.X)
    def __getitem__(self, index):
        return self.X[index], self.Y[index]

training_data = dataset(X_train, y_train)
validation_data = dataset(X_val, y_val)
testing_data = dataset(X_test, y_test)

BATCH_SIZE = 64
EPOCHS = 100
HIDDEN_NEURONS = 10
LR =0.001

train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle= True)
validation_dataloader = DataLoader(validation_data, batch_size=BATCH_SIZE, shuffle= True)
testing_dataloader = DataLoader(testing_data, batch_size=BATCH_SIZE, shuffle= True)

class MyModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.layer_1 = nn.Linear(X.shape[1], HIDDEN_NEURONS)
        self.bn1 = nn.BatchNorm1d(HIDDEN_NEURONS)
        self.layer_2 = nn.Linear(HIDDEN_NEURONS, HIDDEN_NEURONS)
        self.bn2 = nn.BatchNorm1d(HIDDEN_NEURONS)
        self.layer_3 = nn.Linear(HIDDEN_NEURONS, 1)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.3)

    def forward(self, x):
        x = self.dropout(self.relu(self.bn1(self.layer_1(x))))
        x = self.dropout(self.relu(self.bn2(self.layer_2(x))))
        return self.layer_3(x)

model = MyModel().to(device)
print(model)

"""Params=(number of inputs×number of outputs)+number of outputs (biases)

When you create:

**nn.Linear(in_features, out_features)**

PyTorch automatically includes:

**Weights: shape → (out_features, in_features)**

**Bias: shape → (out_features,) (one bias per output neuron)**

Unless you set bias=False, every output neuron has exactly one bias term
"""

model = MyModel().to(device)
summary(model, (X.shape[1],))

criterion = nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-5)

# ADD THIS LINE:
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10, factor=0.5)

total_loss_train = []
total_loss_val = []
total_acc_train = []
total_acc_val = []

# Early stopping variables
best_val_acc = 0
patience_counter = 0
patience = 20

# Training loop
num_epochs = 100
for epoch in range(num_epochs):
    # Training phase
    model.train()
    train_loss = 0.0
    train_preds = []
    train_labels = []
    for inputs, labels in train_dataloader:
        inputs, labels = inputs.to(device), labels.to(device)
        labels = labels.float()
        optimizer.zero_grad()
        outputs = model(inputs).squeeze()
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
        preds = (torch.sigmoid(outputs) > 0.5).float().cpu().numpy()
        train_preds.extend(preds)
        train_labels.extend(labels.cpu().numpy())

    train_loss /= len(train_dataloader)
    train_acc = accuracy_score(train_labels, train_preds)
    total_loss_train.append(train_loss)
    total_acc_train.append(train_acc)

    # Validation phase
    model.eval()
    val_loss = 0.0
    val_preds = []
    val_labels = []
    with torch.no_grad():
        for inputs, labels in validation_dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            labels = labels.float()
            outputs = model(inputs).squeeze()
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            preds = (torch.sigmoid(outputs) > 0.5).float().cpu().numpy()
            val_preds.extend(preds)
            val_labels.extend(labels.cpu().numpy())

    val_loss /= len(validation_dataloader)
    val_acc = accuracy_score(val_labels, val_preds)
    total_loss_val.append(val_loss)
    total_acc_val.append(val_acc)

    # ADD THESE LINES FOR LEARNING RATE SCHEDULING AND EARLY STOPPING:
    scheduler.step(val_loss)  # Update learning rate

    # Early stopping logic
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        patience_counter = 0
        torch.save(model.state_dict(), 'best_model.pth')  # Save best model
    else:
        patience_counter += 1

    if patience_counter >= patience:
        print(f"Early stopping at epoch {epoch+1}")
        break

    # Print progress every 10 epochs
    if (epoch + 1) % 10 == 0:
        current_lr = optimizer.param_groups[0]['lr']
        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, LR: {current_lr:.6f}')

# 5. LOAD BEST MODEL FOR FINAL TESTING (add before your testing section):
model.load_state_dict(torch.load('best_model.pth'))
print(f"Loaded best model with validation accuracy: {best_val_acc:.4f}")

def predict_single_row(model, row, device):
    model.eval()
    with torch.no_grad():
        if isinstance(row, torch.Tensor):
            row_tensor = row.clone().detach().to(device).unsqueeze(0)
        else:
            row_tensor = torch.tensor(row, dtype=torch.float32).to(device).unsqueeze(0)

        output = model(row_tensor)

        # Binary classification case
        predicted_class = torch.round(torch.sigmoid(output)).item()
    return predicted_class

# Pick a row and its true label
row = X_test[0]  # first row from test set
true_label = y_test[0].item()

# Predict
predicted = predict_single_row(model, row, device)

print(f"True label: {true_label}")
print(f"Predicted label: {predicted}")

### TESTING ###
model.eval()
total_loss_test = 0
total_acc_test = 0

with torch.inference_mode():
    for inputs, labels in testing_dataloader:
        inputs, labels = inputs.to(device), labels.to(device)

        # Forward pass
        y_logits = model(inputs).squeeze(1)
        y_pred = torch.round(torch.sigmoid(y_logits))

        # Loss
        loss = criterion(y_logits, labels)
        total_loss_test += loss.item()

        # Accuracy
        total_acc_test += (y_pred == labels).sum().item()

# Print test results
print(f"Test Loss: {total_loss_test / len(testing_dataloader):.4f} | "
      f"Test Acc: {total_acc_test / len(testing_data) * 100:.2f}%")

model.eval()
with torch.inference_mode():
    X_test_tensor = torch.FloatTensor(X_test).to(device)
    y_test_tensor = torch.FloatTensor(y_test).to(device)

    # Get logits and convert to probabilities
    logits = model(X_test_tensor)
    probabilities = torch.sigmoid(logits)
    predictions = (probabilities > 0.5).float()

    # Convert to numpy for plotting
    probs_np = probabilities.cpu().numpy().flatten()
    preds_np = predictions.cpu().numpy().flatten()
    y_test_np = y_test_tensor.cpu().numpy()

fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# Plot 1: Loss curves
axes[0,0].plot(total_loss_train, label='Training Loss', alpha=0.7)
axes[0,0].plot(total_loss_val, label='Validation Loss', alpha=0.7)
axes[0,0].set_title('Training and Validation Loss')
axes[0,0].set_xlabel('Epoch')
axes[0,0].set_ylabel('Loss')
axes[0,0].legend()
axes[0,0].grid(True, alpha=0.3)

# Plot 2: Accuracy curves
axes[0,1].plot([acc*100 for acc in total_acc_train], label='Training Accuracy', alpha=0.7)
axes[0,1].plot([acc*100 for acc in total_acc_val], label='Validation Accuracy', alpha=0.7)
axes[0,1].set_title('Training and Validation Accuracy')
axes[0,1].set_xlabel('Epoch')
axes[0,1].set_ylabel('Accuracy (%)')
axes[0,1].legend()
axes[0,1].grid(True, alpha=0.3)

# Plot 3: Predicted probabilities
axes[1,0].scatter(range(len(probs_np)), probs_np, c=y_test_np, alpha=0.6, cmap='viridis')
axes[1,0].axhline(y=0.5, color='red', linestyle='--', label='Decision Threshold')
axes[1,0].set_xlabel('Sample Index')
axes[1,0].set_ylabel('Predicted Probability')
axes[1,0].set_title('Predicted Probabilities vs True Labels')
axes[1,0].legend()

# Plot 4: Confusion matrix visualization
axes[1,1].scatter(y_test_np, preds_np, alpha=0.6, s=50)
axes[1,1].plot([0, 1], [0, 1], 'r--', label='Perfect Prediction')
axes[1,1].set_xlabel('True Labels')
axes[1,1].set_ylabel('Predicted Labels')
axes[1,1].set_title('Predicted vs True Labels')
axes[1,1].legend()

plt.tight_layout()
plt.show()

final_accuracy = accuracy_score(y_test_np, preds_np)
print(f"Final Test Accuracy: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)")

import torch

# 1. Take one sample from your dataset
single_row = X_test_tensor[0]  # first row
true_label = y_test_tensor[0]  # correct label

# 2. Add batch dimension (model expects [batch_size, features])
single_row = single_row.unsqueeze(0)

# 3. Put model in evaluation mode and disable gradients
model.eval()
with torch.inference_mode():
    pred_logits = model(single_row)  # raw output (logits)
    pred_prob = torch.sigmoid(pred_logits)  # convert to probability for binary classification
    pred_class = torch.round(pred_prob)  # 0 or 1

# 4. Show result
print(f"True label: {true_label.item()}")
print(f"Predicted probability: {pred_prob.item():.4f}")
print(f"Predicted class: {int(pred_class.item())}")

plt.figure(figsize=(8,5))
plt.plot(total_loss_train, label='Train Loss')
plt.plot(total_loss_val, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training vs Validation Loss')
plt.legend()
plt.show()